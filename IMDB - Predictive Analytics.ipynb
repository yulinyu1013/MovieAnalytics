{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from wordcloud import WordCloud,STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "import spacy\n",
    "import re,string,unicodedata\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.stem import LancasterStemmer,WordNetLemmatizer\n",
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = pd.read_csv('Movie_Reviews_100.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label data\n",
    "review['sentiment']= 'negative'\n",
    "review.loc[review['Rating (Out of 10)']>5,'sentiment'] ='positive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    113714\n",
       "negative     13935\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#remove special characters\n",
    "def remove_special_characters(text, remove_digits=True):\n",
    "    pattern=r'[^a-zA-z0-9\\s]'\n",
    "    text=re.sub(pattern,'',text)\n",
    "    return text\n",
    "review['Review']=review['Review'].apply(remove_special_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#stemming\n",
    "def simple_stemmer(text):\n",
    "    ps=nltk.porter.PorterStemmer()\n",
    "    text= ' '.join([ps.stem(word) for word in text.split()])\n",
    "    return text\n",
    "\n",
    "review['stems']=review['Review'].apply(simple_stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from nltk.corpus import stopwords\n",
    "review['stems'] = review['stems'].str.split().apply(lambda x: [word for word in x if word not in stopwords.words('english')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review['stems'] = review['stems'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering - Run everything in this section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Undersampling\n",
    "from imblearn.under_sampling import NearMiss, RandomUnderSampler\n",
    "naive_under_sample = RandomUnderSampler(sampling_strategy = 'majority')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 51.9 s, sys: 4.44 s, total: 56.3 s\n",
      "Wall time: 56.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#BOW\n",
    "from sklearn.model_selection import train_test_split\n",
    "cv=CountVectorizer(min_df=2,max_df=0.95,binary=False,ngram_range=(1,3))\n",
    "cv_reviews=cv.fit_transform(review['stems'].values.astype('U'))\n",
    "cv_X, cv_y = naive_under_sample.fit_resample(cv_reviews, review['sentiment'])\n",
    "X_train_cv, X_test_cv, y_train_cv, y_test_cv = train_test_split(cv_X, cv_y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 59.4 s, sys: 5.96 s, total: 1min 5s\n",
      "Wall time: 1min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#tfidf\n",
    "naive_under_sample2 = RandomUnderSampler(sampling_strategy = 'majority')\n",
    "tv=TfidfVectorizer(min_df=2,max_df=0.95,use_idf=True,ngram_range=(1,3))\n",
    "tv_reviews=tv.fit_transform(review['stems'].values.astype('U'))\n",
    "tv_X, tv_y = naive_under_sample2.fit_resample(tv_reviews, review['sentiment'])\n",
    "X_train_tv, X_test_tv, y_train_tv, y_test_tv = train_test_split(tv_X, tv_y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.4 s, sys: 2.23 s, total: 14.6 s\n",
      "Wall time: 14.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#BOW\n",
    "from imblearn.over_sampling import SMOTE\n",
    "cv_smote_over_sample = SMOTE(sampling_strategy='minority')\n",
    "cv_over_X, cv_over_y = cv_smote_over_sample.fit_resample(cv_reviews, review['sentiment'])\n",
    "X_train_cv_o, X_test_cv_o, y_train_cv_o, y_test_cv_o = train_test_split(cv_over_X, cv_over_y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.1 s, sys: 3.82 s, total: 18.9 s\n",
      "Wall time: 19.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#tdidf\n",
    "tv_smote_over_sample = SMOTE(sampling_strategy='minority')\n",
    "tv_over_X, tv_over_y = tv_smote_over_sample.fit_resample(tv_reviews, review['sentiment'])\n",
    "X_train_tv_o, X_test_tv_o, y_train_tv_o, y_test_tv_o = train_test_split(tv_over_X, tv_over_y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 38min 31s, sys: 31.3 s, total: 39min 2s\n",
      "Wall time: 7min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lr_cv_u=LogisticRegression(penalty='l2',max_iter=500,C=1,random_state=42)\n",
    "lr_cv_o=LogisticRegression(penalty='l2',max_iter=500,C=1,random_state=42)\n",
    "lr_tv_u=LogisticRegression(penalty='l2',max_iter=500,C=1,random_state=42)\n",
    "lr_tv_o=LogisticRegression(penalty='l2',max_iter=500,C=1,random_state=42)\n",
    "\n",
    "#Fitting the model for Bag of words\n",
    "lr_bow_u=lr_cv_u.fit(X_train_cv,y_train_cv)\n",
    "lr_bow_o=lr_cv_o.fit(X_train_cv_o,y_train_cv_o)\n",
    "\n",
    "#Fitting the model for tfidf features\n",
    "lr_tfidf_u=lr_tv_u.fit(X_train_tv,y_train_tv)\n",
    "lr_tfidf_o=lr_tv_o.fit(X_train_tv_o,y_train_tv_o)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting the model for bag of words\n",
    "\n",
    "lr_bow_u_predict=lr_cv_u.predict(X_test_cv)\n",
    "lr_bow_o_predict=lr_cv_o.predict(X_test_cv_o)\n",
    "\n",
    "##Predicting the model for tfidf features\n",
    "lr_tfidf_u_predict=lr_tv_u.predict(X_test_tv)\n",
    "lr_tfidf_o_predict=lr_tv_o.predict(X_test_tv_o)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_bow_u_score : 0.8754933620380337\n",
      "lr_bow_o_score : 0.9401354262850108\n",
      "lr_tfidf_u_score : 0.8742375313957661\n",
      "lr_tfidf_o_score : 0.9408609242404257\n"
     ]
    }
   ],
   "source": [
    "print(\"lr_bow_u_score :\",accuracy_score(y_test_cv,lr_bow_u_predict))\n",
    "print(\"lr_bow_o_score :\",accuracy_score(y_test_cv_o,lr_bow_o_predict))\n",
    "print(\"lr_tfidf_u_score :\",accuracy_score(y_test_tv,lr_tfidf_u_predict))\n",
    "print(\"lr_tfidf_o_score :\",accuracy_score(y_test_tv_o,lr_tfidf_o_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.88      0.87      0.88      2796\n",
      "    negative       0.87      0.88      0.88      2778\n",
      "\n",
      "    accuracy                           0.88      5574\n",
      "   macro avg       0.88      0.88      0.88      5574\n",
      "weighted avg       0.88      0.88      0.88      5574\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.93      0.96      0.94     22881\n",
      "    negative       0.95      0.92      0.94     22605\n",
      "\n",
      "    accuracy                           0.94     45486\n",
      "   macro avg       0.94      0.94      0.94     45486\n",
      "weighted avg       0.94      0.94      0.94     45486\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.88      0.87      0.87      2796\n",
      "    negative       0.87      0.88      0.87      2778\n",
      "\n",
      "    accuracy                           0.87      5574\n",
      "   macro avg       0.87      0.87      0.87      5574\n",
      "weighted avg       0.87      0.87      0.87      5574\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.91      0.97      0.94     22881\n",
      "    negative       0.97      0.91      0.94     22605\n",
      "\n",
      "    accuracy                           0.94     45486\n",
      "   macro avg       0.94      0.94      0.94     45486\n",
      "weighted avg       0.94      0.94      0.94     45486\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_bow_u_report=classification_report(y_test_cv,lr_bow_u_predict,target_names=['positive','negative'])\n",
    "print(lr_bow_u_report)\n",
    "\n",
    "lr_bow_o_report=classification_report(y_test_cv_o,lr_bow_o_predict,target_names=['positive','negative'])\n",
    "print(lr_bow_o_report)\n",
    "\n",
    "lr_tfidf_u_report=classification_report(y_test_tv,lr_tfidf_u_predict,target_names=['positive','negative'])\n",
    "print(lr_tfidf_u_report)\n",
    "\n",
    "lr_tfidf_o_report=classification_report(y_test_tv_o,lr_tfidf_o_predict,target_names=['positive','negative'])\n",
    "print(lr_tfidf_o_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.3 s, sys: 820 ms, total: 15.2 s\n",
      "Wall time: 9.48 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "svm_cv_u=SGDClassifier(loss='hinge',max_iter=500,random_state=42)\n",
    "svm_cv_o=SGDClassifier(loss='hinge',max_iter=500,random_state=42)\n",
    "svm_tv_u=SGDClassifier(loss='hinge',max_iter=500,random_state=42)\n",
    "svm_tv_o=SGDClassifier(loss='hinge',max_iter=500,random_state=42)\n",
    "\n",
    "#Fitting the model for Bag of words\n",
    "svm_bow_u=svm_cv_u.fit(X_train_cv,y_train_cv)\n",
    "svm_bow_o=svm_cv_o.fit(X_train_cv_o,y_train_cv_o)\n",
    "\n",
    "#Fitting the model for tfidf features\n",
    "svm_tfidf_u=svm_tv_u.fit(X_train_tv,y_train_tv)\n",
    "svm_tfidf_o=svm_tv_o.fit(X_train_tv_o,y_train_tv_o)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting the model for bag of words\n",
    "\n",
    "svm_bow_u_predict=svm_cv_u.predict(X_test_cv)\n",
    "svm_bow_o_predict=svm_cv_o.predict(X_test_cv_o)\n",
    "\n",
    "##Predicting the model for tfidf features\n",
    "svm_tfidf_u_predict=svm_tv_u.predict(X_test_tv)\n",
    "svm_tfidf_o_predict=svm_tv_o.predict(X_test_tv_o)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm_bow_u_score : 0.8697524219590959\n",
      "svm_bow_o_score : 0.9383766433627929\n",
      "svm_tfidf_u_score : 0.877108001435235\n",
      "svm_tfidf_o_score : 0.8970892142637295\n"
     ]
    }
   ],
   "source": [
    "print(\"svm_bow_u_score :\",accuracy_score(y_test_cv,svm_bow_u_predict))\n",
    "print(\"svm_bow_o_score :\",accuracy_score(y_test_cv_o,svm_bow_o_predict))\n",
    "print(\"svm_tfidf_u_score :\",accuracy_score(y_test_tv,svm_tfidf_u_predict))\n",
    "print(\"svm_tfidf_o_score :\",accuracy_score(y_test_tv_o,svm_tfidf_o_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.88      0.86      0.87      2796\n",
      "    negative       0.86      0.88      0.87      2778\n",
      "\n",
      "    accuracy                           0.87      5574\n",
      "   macro avg       0.87      0.87      0.87      5574\n",
      "weighted avg       0.87      0.87      0.87      5574\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.92      0.96      0.94     22881\n",
      "    negative       0.96      0.92      0.94     22605\n",
      "\n",
      "    accuracy                           0.94     45486\n",
      "   macro avg       0.94      0.94      0.94     45486\n",
      "weighted avg       0.94      0.94      0.94     45486\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.88      0.88      0.88      2796\n",
      "    negative       0.87      0.88      0.88      2778\n",
      "\n",
      "    accuracy                           0.88      5574\n",
      "   macro avg       0.88      0.88      0.88      5574\n",
      "weighted avg       0.88      0.88      0.88      5574\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.86      0.95      0.90     22881\n",
      "    negative       0.94      0.85      0.89     22605\n",
      "\n",
      "    accuracy                           0.90     45486\n",
      "   macro avg       0.90      0.90      0.90     45486\n",
      "weighted avg       0.90      0.90      0.90     45486\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_bow_u_report=classification_report(y_test_cv,svm_bow_u_predict,target_names=['positive','negative'])\n",
    "print(svm_bow_u_report)\n",
    "\n",
    "svm_bow_o_report=classification_report(y_test_cv_o,svm_bow_o_predict,target_names=['positive','negative'])\n",
    "print(svm_bow_o_report)\n",
    "\n",
    "svm_tfidf_u_report=classification_report(y_test_tv,svm_tfidf_u_predict,target_names=['positive','negative'])\n",
    "print(svm_tfidf_u_report)\n",
    "\n",
    "svm_tfidf_o_report=classification_report(y_test_tv_o,svm_tfidf_o_predict,target_names=['positive','negative'])\n",
    "print(svm_tfidf_o_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.65 s, sys: 144 ms, total: 2.79 s\n",
      "Wall time: 2.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mnb_cv_u=MultinomialNB()\n",
    "mnb_cv_o=MultinomialNB()\n",
    "mnb_tv_u=MultinomialNB()\n",
    "mnb_tv_o=MultinomialNB()\n",
    "\n",
    "#Fitting the model for Bag of words\n",
    "mnb_bow_u=mnb_cv_u.fit(X_train_cv,y_train_cv)\n",
    "mnb_bow_o=mnb_cv_o.fit(X_train_cv_o,y_train_cv_o)\n",
    "\n",
    "#Fitting the model for tfidf features\n",
    "mnb_tfidf_u=mnb_tv_u.fit(X_train_tv,y_train_tv)\n",
    "mnb_tfidf_o=mnb_tv_o.fit(X_train_tv_o,y_train_tv_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting the model for bag of words\n",
    "\n",
    "mnb_bow_u_predict=mnb_cv_u.predict(X_test_cv)\n",
    "mnb_bow_o_predict=mnb_cv_o.predict(X_test_cv_o)\n",
    "\n",
    "##Predicting the model for tfidf features\n",
    "mnb_tfidf_u_predict=mnb_tv_u.predict(X_test_tv)\n",
    "mnb_tfidf_o_predict=mnb_tv_o.predict(X_test_tv_o)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnb_bow_u_score : 0.8711876569788303\n",
      "mnb_bow_o_score : 0.8585938530536869\n",
      "mnb_tfidf_u_score : 0.8783638320775027\n",
      "mnb_tfidf_o_score : 0.9601415820252386\n"
     ]
    }
   ],
   "source": [
    "print(\"mnb_bow_u_score :\",accuracy_score(y_test_cv,mnb_bow_u_predict))\n",
    "print(\"mnb_bow_o_score :\",accuracy_score(y_test_cv_o,mnb_bow_o_predict))\n",
    "print(\"mnb_tfidf_u_score :\",accuracy_score(y_test_tv,mnb_tfidf_u_predict))\n",
    "print(\"mnb_tfidf_o_score :\",accuracy_score(y_test_tv_o,mnb_tfidf_o_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.85      0.90      0.87      2796\n",
      "    negative       0.89      0.85      0.87      2778\n",
      "\n",
      "    accuracy                           0.87      5574\n",
      "   macro avg       0.87      0.87      0.87      5574\n",
      "weighted avg       0.87      0.87      0.87      5574\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.93      0.77      0.85     22881\n",
      "    negative       0.81      0.94      0.87     22605\n",
      "\n",
      "    accuracy                           0.86     45486\n",
      "   macro avg       0.87      0.86      0.86     45486\n",
      "weighted avg       0.87      0.86      0.86     45486\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.85      0.92      0.88      2796\n",
      "    negative       0.91      0.84      0.87      2778\n",
      "\n",
      "    accuracy                           0.88      5574\n",
      "   macro avg       0.88      0.88      0.88      5574\n",
      "weighted avg       0.88      0.88      0.88      5574\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.95      0.97      0.96     22881\n",
      "    negative       0.97      0.95      0.96     22605\n",
      "\n",
      "    accuracy                           0.96     45486\n",
      "   macro avg       0.96      0.96      0.96     45486\n",
      "weighted avg       0.96      0.96      0.96     45486\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mnb_bow_u_report=classification_report(y_test_cv,mnb_bow_u_predict,target_names=['positive','negative'])\n",
    "print(mnb_bow_u_report)\n",
    "\n",
    "mnb_bow_o_report=classification_report(y_test_cv_o,mnb_bow_o_predict,target_names=['positive','negative'])\n",
    "print(mnb_bow_o_report)\n",
    "\n",
    "mnb_tfidf_u_report=classification_report(y_test_tv,mnb_tfidf_u_predict,target_names=['positive','negative'])\n",
    "print(mnb_tfidf_u_report)\n",
    "\n",
    "mnb_tfidf_o_report=classification_report(y_test_tv_o,mnb_tfidf_o_predict,target_names=['positive','negative'])\n",
    "print(mnb_tfidf_o_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 1min 58s, sys: 1min 16s, total: 1h 3min 15s\n",
      "Wall time: 9min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xbg_cv_u=XGBClassifier(random_state=42,learning_rate=0.9)\n",
    "xbg_cv_o=XGBClassifier(random_state=42,learning_rate=0.9)\n",
    "xbg_tv_u=XGBClassifier(random_state=42,learning_rate=0.9)\n",
    "xbg_tv_o=XGBClassifier(random_state=42,learning_rate=0.9)\n",
    "\n",
    "#Fitting the model for Bag of words\n",
    "xbg_bow_u=xbg_cv_u.fit(X_train_cv,y_train_cv)\n",
    "xbg_bow_o=xbg_cv_o.fit(X_train_cv_o,y_train_cv_o)\n",
    "\n",
    "#Fitting the model for tfidf features\n",
    "xbg_tfidf_u=xbg_tv_u.fit(X_train_tv,y_train_tv)\n",
    "xbg_tfidf_o=xbg_tv_o.fit(X_train_tv_o,y_train_tv_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting the model for bag of words\n",
    "xbg_bow_u_predict=xbg_cv_u.predict(X_test_cv)\n",
    "xbg_bow_o_predict=xbg_cv_o.predict(X_test_cv_o)\n",
    "\n",
    "##Predicting the model for tfidf features\n",
    "xbg_tfidf_u_predict=xbg_tv_u.predict(X_test_tv)\n",
    "xbg_tfidf_o_predict=xbg_tv_o.predict(X_test_tv_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xbg_bow_u_score : 0.826157158234661\n",
      "xbg_bow_o_score : 0.9535681308534494\n",
      "xbg_tfidf_u_score : 0.8252601363473269\n",
      "xbg_tfidf_o_score : 0.9331442641691949\n"
     ]
    }
   ],
   "source": [
    "print(\"xbg_bow_u_score :\",accuracy_score(y_test_cv,xbg_bow_u_predict))\n",
    "print(\"xbg_bow_o_score :\",accuracy_score(y_test_cv_o,xbg_bow_o_predict))\n",
    "print(\"xbg_tfidf_u_score :\",accuracy_score(y_test_tv,xbg_tfidf_u_predict))\n",
    "print(\"xbg_tfidf_o_score :\",accuracy_score(y_test_tv_o,xbg_tfidf_o_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.83      0.82      0.83      2796\n",
      "    negative       0.82      0.83      0.83      2778\n",
      "\n",
      "    accuracy                           0.83      5574\n",
      "   macro avg       0.83      0.83      0.83      5574\n",
      "weighted avg       0.83      0.83      0.83      5574\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.97      0.94      0.95     22881\n",
      "    negative       0.94      0.97      0.95     22605\n",
      "\n",
      "    accuracy                           0.95     45486\n",
      "   macro avg       0.95      0.95      0.95     45486\n",
      "weighted avg       0.95      0.95      0.95     45486\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.83      0.82      0.83      2796\n",
      "    negative       0.82      0.83      0.83      2778\n",
      "\n",
      "    accuracy                           0.83      5574\n",
      "   macro avg       0.83      0.83      0.83      5574\n",
      "weighted avg       0.83      0.83      0.83      5574\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.94      0.93      0.93     22881\n",
      "    negative       0.93      0.93      0.93     22605\n",
      "\n",
      "    accuracy                           0.93     45486\n",
      "   macro avg       0.93      0.93      0.93     45486\n",
      "weighted avg       0.93      0.93      0.93     45486\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xbg_bow_u_report=classification_report(y_test_cv,xbg_bow_u_predict,target_names=['positive','negative'])\n",
    "print(xbg_bow_u_report)\n",
    "\n",
    "xbg_bow_o_report=classification_report(y_test_cv_o,xbg_bow_o_predict,target_names=['positive','negative'])\n",
    "print(xbg_bow_o_report)\n",
    "\n",
    "xbg_tfidf_u_report=classification_report(y_test_tv,xbg_tfidf_u_predict,target_names=['positive','negative'])\n",
    "print(xbg_tfidf_u_report)\n",
    "\n",
    "xbg_tfidf_o_report=classification_report(y_test_tv_o,xbg_tfidf_o_predict,target_names=['positive','negative'])\n",
    "print(xbg_tfidf_o_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 53min 13s, sys: 12.1 s, total: 53min 25s\n",
      "Wall time: 53min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dct_cv_u=DecisionTreeClassifier(random_state=42,criterion='entropy')\n",
    "dct_cv_o=DecisionTreeClassifier(random_state=42,criterion='entropy')\n",
    "dct_tv_u=DecisionTreeClassifier(random_state=42,criterion='entropy')\n",
    "dct_tv_o=DecisionTreeClassifier(random_state=42,criterion='entropy')\n",
    "\n",
    "#Fitting the model for Bag of words\n",
    "dct_bow_u=dct_cv_u.fit(X_train_cv,y_train_cv)\n",
    "dct_bow_o=dct_cv_o.fit(X_train_cv_o,y_train_cv_o)\n",
    "\n",
    "#Fitting the model for tfidf features\n",
    "dct_tfidf_u=dct_tv_u.fit(X_train_tv,y_train_tv)\n",
    "dct_tfidf_o=dct_tv_o.fit(X_train_tv_o,y_train_tv_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting the model for bag of words\n",
    "dct_bow_u_predict=dct_cv_u.predict(X_test_cv)\n",
    "dct_bow_o_predict=dct_cv_o.predict(X_test_cv_o)\n",
    "\n",
    "##Predicting the model for tfidf features\n",
    "dct_tfidf_u_predict=dct_tv_u.predict(X_test_tv)\n",
    "dct_tfidf_o_predict=dct_tv_o.predict(X_test_tv_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dct_bow_u_score : 0.7054180121994976\n",
      "dct_bow_o_score : 0.8821175746383503\n",
      "dct_tfidf_u_score : 0.7206673842841765\n",
      "dct_tfidf_o_score : 0.8930440135426285\n"
     ]
    }
   ],
   "source": [
    "print(\"dct_bow_u_score :\",accuracy_score(y_test_cv,dct_bow_u_predict))\n",
    "print(\"dct_bow_o_score :\",accuracy_score(y_test_cv_o,dct_bow_o_predict))\n",
    "print(\"dct_tfidf_u_score :\",accuracy_score(y_test_tv,dct_tfidf_u_predict))\n",
    "print(\"dct_tfidf_o_score :\",accuracy_score(y_test_tv_o,dct_tfidf_o_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.71      0.70      0.70      2796\n",
      "    negative       0.70      0.71      0.71      2778\n",
      "\n",
      "    accuracy                           0.71      5574\n",
      "   macro avg       0.71      0.71      0.71      5574\n",
      "weighted avg       0.71      0.71      0.71      5574\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.87      0.90      0.88     22881\n",
      "    negative       0.90      0.86      0.88     22605\n",
      "\n",
      "    accuracy                           0.88     45486\n",
      "   macro avg       0.88      0.88      0.88     45486\n",
      "weighted avg       0.88      0.88      0.88     45486\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.72      0.72      0.72      2796\n",
      "    negative       0.72      0.72      0.72      2778\n",
      "\n",
      "    accuracy                           0.72      5574\n",
      "   macro avg       0.72      0.72      0.72      5574\n",
      "weighted avg       0.72      0.72      0.72      5574\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.88      0.91      0.90     22881\n",
      "    negative       0.91      0.87      0.89     22605\n",
      "\n",
      "    accuracy                           0.89     45486\n",
      "   macro avg       0.89      0.89      0.89     45486\n",
      "weighted avg       0.89      0.89      0.89     45486\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dct_bow_u_report=classification_report(y_test_cv,dct_bow_u_predict,target_names=['positive','negative'])\n",
    "print(dct_bow_u_report)\n",
    "\n",
    "dct_bow_o_report=classification_report(y_test_cv_o,dct_bow_o_predict,target_names=['positive','negative'])\n",
    "print(dct_bow_o_report)\n",
    "\n",
    "dct_tfidf_u_report=classification_report(y_test_tv,dct_tfidf_u_predict,target_names=['positive','negative'])\n",
    "print(dct_tfidf_u_report)\n",
    "\n",
    "dct_tfidf_o_report=classification_report(y_test_tv_o,dct_tfidf_o_predict,target_names=['positive','negative'])\n",
    "print(dct_tfidf_o_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
